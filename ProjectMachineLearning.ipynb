{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cJ8XXLLscAtR"
      },
      "outputs": [],
      "source": [
        "import chess\n",
        "\n",
        "def moves_to_mate(fen, solution_moves):\n",
        "    board = chess.Board(fen)\n",
        "    move_count = 0\n",
        "\n",
        "    for uci in solution_moves:\n",
        "        move = chess.Move.from_uci(uci)\n",
        "        if move in board.legal_moves:\n",
        "            board.push(move)\n",
        "            if board.turn == chess.WHITE:  # full move completed (after Blackâ€™s move)\n",
        "                move_count += 1\n",
        "        else:\n",
        "            return 0  # illegal move, not a valid mate sequence\n",
        "\n",
        "    return move_count if board.is_checkmate() else 0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import chess\n",
        "# Utility: convert FEN to tensor with positional features\n",
        "def fen_to_tensor(fen):\n",
        "    board = chess.Board(fen)\n",
        "    # Base piece planes: 12 channels\n",
        "    planes = np.zeros((12, 8, 8), dtype=np.float32)\n",
        "    for sq, piece in board.piece_map().items():\n",
        "        idx = {'P':0,'N':1,'B':2,'R':3,'Q':4,'K':5}[piece.symbol().upper()]\n",
        "        color_offset = 0 if piece.color == chess.WHITE else 6\n",
        "        row = 7 - (sq // 8)\n",
        "        col = sq % 8\n",
        "        planes[idx + color_offset, row, col] = 1\n",
        "\n",
        "    # Side to move plane\n",
        "    stm_plane = np.full((1, 8, 8), float(board.turn), dtype=np.float32)\n",
        "\n",
        "    # Additional positional features: 7 channels\n",
        "    # Attack maps (white, black)\n",
        "    attack_w = np.zeros((8, 8), dtype=np.float32)\n",
        "    attack_b = np.zeros((8, 8), dtype=np.float32)\n",
        "    for sq in chess.SQUARES:\n",
        "        r = 7 - (sq // 8)\n",
        "        c = sq % 8\n",
        "        if board.attackers(chess.WHITE, sq):\n",
        "            attack_w[r, c] = 1\n",
        "        if board.attackers(chess.BLACK, sq):\n",
        "            attack_b[r, c] = 1\n",
        "\n",
        "    # Legal move mask\n",
        "    legal_mask = np.zeros((8, 8), dtype=np.float32)\n",
        "    for mv in board.legal_moves:\n",
        "        r = 7 - (mv.to_square // 8)\n",
        "        c = mv.to_square % 8\n",
        "        legal_mask[r, c] = 1\n",
        "\n",
        "    # Distance to kings\n",
        "    dist_wk = np.zeros((8, 8), dtype=np.float32)\n",
        "    dist_bk = np.zeros((8, 8), dtype=np.float32)\n",
        "    wksq = board.king(chess.WHITE)\n",
        "    bksq = board.king(chess.BLACK)\n",
        "    for sq in chess.SQUARES:\n",
        "        r = 7 - (sq // 8)\n",
        "        c = sq % 8\n",
        "        if wksq is not None:\n",
        "            dist_wk[r, c] = chess.square_distance(sq, wksq)\n",
        "        if bksq is not None:\n",
        "            dist_bk[r, c] = chess.square_distance(sq, bksq)\n",
        "\n",
        "    # Check status plane\n",
        "    check_pl = np.full((8, 8), float(board.is_check()), dtype=np.float32)\n",
        "\n",
        "    # Pinned pieces map\n",
        "    pinned = np.zeros((8, 8), dtype=np.float32)\n",
        "    for sq in chess.SQUARES:\n",
        "        piece = board.piece_at(sq)\n",
        "        if piece and board.is_pinned(piece.color, sq):\n",
        "            r = 7 - (sq // 8)\n",
        "            c = sq % 8\n",
        "            pinned[r, c] = 1\n",
        "    # Checking moves mask\n",
        "    checking_moves_mask = np.zeros((8,8), dtype=np.float32)\n",
        "    for mv in board.legal_moves:\n",
        "        board.push(mv)\n",
        "        if board.is_check():\n",
        "            r = 7 - (mv.to_square // 8)\n",
        "            c = mv.to_square % 8\n",
        "            checking_moves_mask[r, c] = 1\n",
        "        board.pop()\n",
        "\n",
        "    controlled_white = np.zeros((8,8), dtype=np.float32)\n",
        "    controlled_black = np.zeros((8,8), dtype=np.float32)\n",
        "    for sq in chess.SQUARES:\n",
        "        r = 7 - (sq // 8)\n",
        "        c = sq % 8\n",
        "        white_attackers = len(board.attackers(chess.WHITE, sq))\n",
        "        black_attackers = len(board.attackers(chess.BLACK, sq))\n",
        "        if white_attackers > black_attackers:\n",
        "            controlled_white[r, c] = 1.0\n",
        "        elif black_attackers > white_attackers:\n",
        "            controlled_black[r, c] = 1.0\n",
        "\n",
        "     # Stack all planes: 12 + 1 + 2 + 1 + 2 + 1 + 1 + 2 = 22 channels\n",
        "    extra = [attack_w, attack_b, legal_mask, dist_wk, dist_bk, check_pl, pinned, controlled_white, controlled_black, checking_moves_mask]\n",
        "    feature_planes = np.stack(extra, axis=0)\n",
        "    all_planes = np.concatenate([planes, stm_plane, feature_planes], axis=0)\n",
        "\n",
        "    return torch.from_numpy(all_planes)\n"
      ],
      "metadata": {
        "id": "zwpzlEl8jtTS"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Hyperparameters & Constants ---\n",
        "EPOCHS = 1                # Number of epochs to train\n",
        "BATCH_SIZE = 512          # Number of samples per batch\n",
        "MAX_BATCHES_PER_EPOCH = 600  # Process exactly 600 batches per epoch\n",
        "LR = 1e-2                 # Learning rate\n",
        "BINARY_CLASSES = 2        # Number of classes for binary classification\n",
        "DATA_PATH = 'data/trainingpuzzles.csv'\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Use more workers but be mindful of CPU limits\n",
        "train_loader = DataLoader(..., batch_size=32, num_workers=4, pin_memory=False)\n",
        "\n",
        "# Limit PyTorch CPU threads\n",
        "torch.set_num_threads(4)\n",
        "\n",
        "# Precompute fen tensors once outside of training\n",
        "# Save processed tensors to disk, then load quickly during training\n",
        "\n",
        "class NumberMateCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NumberMateCNN, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(23, 32, 3, padding=1), nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
        "            nn.Conv2d(64, 128, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2)\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Flatten(), nn.Linear(128*2*2, 256), nn.ReLU(), nn.Dropout(0.5),\n",
        "            nn.Linear(256, 1)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        out = self.fc(self.conv(x)).squeeze(-1)\n",
        "        return torch.sigmoid(out)  # outputs in [0,1]\n",
        "\n",
        "# Binary classification model\n",
        "class IsMateCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(IsMateCNN, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(23, 32, 3, padding=1), nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
        "            nn.Conv2d(64, 128, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2)\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Flatten(), nn.Linear(128*2*2, 256), nn.ReLU(), nn.Dropout(0.5),\n",
        "            nn.Linear(256, BINARY_CLASSES)\n",
        "        )\n",
        "    def forward(self, x): return self.fc(self.conv(x))\n",
        "\n",
        "import json\n",
        "\n",
        "def train_binary(model, train_loader, val_loader, device, save_path='binary_model.pt', max_batches=600):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "    model.to(device)\n",
        "\n",
        "    avg_train_losses = []\n",
        "    avg_val_losses = []\n",
        "    val_accuracies = []\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        batch_count = 0\n",
        "        samples_seen = 0\n",
        "\n",
        "        for x, y in train_loader:\n",
        "            if batch_count >= max_batches:\n",
        "                break\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(x)\n",
        "            loss = criterion(logits, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item() * x.size(0)\n",
        "            samples_seen += x.size(0)\n",
        "            batch_count += 1\n",
        "\n",
        "        avg_train_loss = total_loss / samples_seen\n",
        "        avg_train_losses.append(avg_train_loss)\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for x_val, y_val in val_loader:\n",
        "                x_val, y_val = x_val.to(device), y_val.to(device)\n",
        "                logits = model(x_val)\n",
        "                loss = criterion(logits, y_val)\n",
        "                val_loss += loss.item() * x_val.size(0)\n",
        "                preds = logits.argmax(dim=1)\n",
        "                correct += (preds == y_val).sum().item()\n",
        "                total += y_val.size(0)\n",
        "\n",
        "        avg_val_loss = val_loss / total\n",
        "        val_accuracy = correct / total\n",
        "\n",
        "        avg_val_losses.append(avg_val_loss)\n",
        "        val_accuracies.append(val_accuracy)\n",
        "\n",
        "        print(f\"Epoch {epoch+1} Train Loss: {avg_train_loss:.4f} Val Loss: {avg_val_loss:.4f} Val Acc: {val_accuracy:.4f}\")\n",
        "\n",
        "        torch.save(model.state_dict(), f\"{save_path}_epoch{epoch+1}.pt\")\n",
        "\n",
        "    # Save metrics to JSON file\n",
        "    with open(f\"{save_path}_metrics.json\", 'w') as f:\n",
        "        json.dump({\n",
        "            'train_loss': avg_train_losses,\n",
        "            'val_loss': avg_val_losses,\n",
        "            'val_accuracy': val_accuracies\n",
        "        }, f)\n",
        "\n",
        "def validate_distance(model, loader, device, criterion):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    total_samples = 0\n",
        "    with torch.no_grad():\n",
        "        for x, t in loader:\n",
        "            x, t = x.to(device), t.to(device)\n",
        "            t_recip = torch.where(t > 0, 1.0 / t, torch.zeros_like(t))\n",
        "            pred = model(x)\n",
        "            loss = criterion(pred, t_recip)\n",
        "            total_loss += loss.item() * x.size(0)\n",
        "            total_samples += x.size(0)\n",
        "    avg_loss = total_loss / total_samples\n",
        "    return avg_loss\n",
        "\n",
        "\n",
        "import json\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "def train_distance(model, train_loader, val_loader, device, save_path='distance_model.pt'):\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "    model.to(device)\n",
        "\n",
        "    EPOCHS = 30\n",
        "    error_threshold = 1  # acceptable error threshold in mate moves\n",
        "\n",
        "    avg_train_losses = []\n",
        "    avg_val_losses = []\n",
        "    val_accuracies = []\n",
        "    val_mean_abs_errors = []\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        model.train()\n",
        "        total_train_loss = 0\n",
        "        for x, t in train_loader:\n",
        "            x, t = x.to(device), t.to(device)\n",
        "            # target: inverse mate distance (1/mate_moves), 0 if no mate\n",
        "            t_recip = torch.where(t > 0, 1.0 / t, torch.zeros_like(t))\n",
        "            optimizer.zero_grad()\n",
        "            pred = model(x)\n",
        "            loss = criterion(pred, t_recip)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_train_loss += loss.item() * x.size(0)\n",
        "        avg_train_loss = total_train_loss / len(train_loader.dataset)\n",
        "        avg_train_losses.append(avg_train_loss)\n",
        "\n",
        "        # --- Validation ---\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        abs_error_sum = 0\n",
        "        correct_within_threshold = 0\n",
        "        total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for x_val, t_val in val_loader:\n",
        "                x_val, t_val = x_val.to(device), t_val.to(device)\n",
        "                t_recip_val = torch.where(t_val > 0, 1.0 / t_val, torch.zeros_like(t_val))\n",
        "                pred_val = model(x_val)\n",
        "\n",
        "                loss_val = criterion(pred_val, t_recip_val)\n",
        "                val_loss += loss_val.item() * x_val.size(0)\n",
        "\n",
        "                # Convert predictions back to mate moves\n",
        "                pred_moves = torch.where(pred_val > 0, 1.0 / pred_val, torch.full_like(pred_val, 1000.0))\n",
        "                abs_move_errors = torch.abs(pred_moves - t_val)\n",
        "\n",
        "                abs_error_sum += abs_move_errors.sum().item()\n",
        "                correct_within_threshold += (abs_move_errors <= error_threshold).sum().item()\n",
        "                total += t_val.size(0)\n",
        "\n",
        "        avg_val_loss = val_loss / len(val_loader.dataset)\n",
        "        avg_val_losses.append(avg_val_loss)\n",
        "\n",
        "        mean_abs_error = abs_error_sum / total\n",
        "        val_mean_abs_errors.append(mean_abs_error)\n",
        "\n",
        "        val_accuracy = correct_within_threshold / total\n",
        "        val_accuracies.append(val_accuracy)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}: Train Loss={avg_train_loss:.4f}, Val Loss={avg_val_loss:.4f}, Val Acc={val_accuracy:.4f}, Mean Abs Error={mean_abs_error:.4f} moves\")\n",
        "\n",
        "        torch.save(model.state_dict(), f\"{save_path}_epoch{epoch+1}.pt\")\n",
        "\n",
        "    # Save metrics to JSON\n",
        "    with open(f\"{save_path}_metrics.json\", 'w') as f:\n",
        "        json.dump({\n",
        "            'train_loss': avg_train_losses,\n",
        "            'val_loss': avg_val_losses,\n",
        "            'val_accuracy': val_accuracies,\n",
        "            'val_mean_abs_error': val_mean_abs_errors\n",
        "        }, f)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WVX7N2OmcDwL"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# --- Constants ---\n",
        "EPOCHS = 1\n",
        "BATCH_SIZE = 512\n",
        "LR = 1e-2\n",
        "BINARY_CLASSES = 2\n",
        "DATA_PATH = 'data/trainingpuzzles.csv'\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# --- Dataset class (uses your fen_to_tensor and parses labels accordingly) ---\n",
        "class ChessPuzzleBinaryDataset(Dataset):\n",
        "    def __init__(self, csv_file, task='binary'):\n",
        "        self.df = pd.read_csv(csv_file)\n",
        "        self.task = task  # 'binary' or 'distance'\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        fen = row['FEN']\n",
        "        moves = row['Moves']\n",
        "        x = fen_to_tensor(fen)\n",
        "\n",
        "        if self.task == 'binary':\n",
        "            # Label: 1 if it's a mate puzzle (contains \"#\"), else 0\n",
        "            is_mate = 1 if '#' in moves else 0\n",
        "            y = torch.tensor(is_mate, dtype=torch.long)\n",
        "        else:\n",
        "            # Distance: number of moves in mate (e.g., \"1. Qh5#\")\n",
        "            try:\n",
        "                move_list = moves.strip().split()\n",
        "                mate_move = next((m for m in move_list if '#' in m), None)\n",
        "                mate_dist = int(mate_move.replace('#', '')[-1]) if mate_move else 0\n",
        "            except:\n",
        "                mate_dist = 0\n",
        "            y = torch.tensor(mate_dist, dtype=torch.float32)\n",
        "        return x, y\n",
        "\n",
        "# --- Load and split dataset ---\n",
        "full_ds = ChessPuzzleBinaryDataset(DATA_PATH, task='binary')\n",
        "indices = list(range(len(full_ds)))\n",
        "train_idx, val_idx = train_test_split(indices, test_size=0.1, random_state=42)\n",
        "\n",
        "train_loader = DataLoader(Subset(full_ds, train_idx), batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
        "val_loader   = DataLoader(Subset(full_ds, val_idx), batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
        "\n",
        "# --- Train binary classification model ---\n",
        "binary_model = IsMateCNN()\n",
        "train_binary(binary_model, train_loader, val_loader, DEVICE, save_path='binary_model')\n",
        "\n",
        "# --- Switch dataset mode to distance regression ---\n",
        "full_ds.task = 'distance'\n",
        "train_loader = DataLoader(Subset(full_ds, train_idx), batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
        "\n",
        "# --- Train mate-distance regression model ---\n",
        "distance_model = NumberMateCNN()\n",
        "train_distance(distance_model, val_loader, train_loader, DEVICE, save_path='distance_model')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "DdOmEeXAdA92",
        "outputId": "9c056794-4a06-499e-ab32-7867c03e66b4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Train Loss: 0.0012 Val Loss: 0.0000 Val Acc: 1.0000\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "train_distance() missing 1 required positional argument: 'device'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-9a1bd58d6741>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;31m# --- Train mate-distance regression model ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0mdistance_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNumberMateCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m \u001b[0mtrain_distance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistance_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'distance_model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: train_distance() missing 1 required positional argument: 'device'"
          ]
        }
      ]
    }
  ]
}